{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scott\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('data/melb_data_ps.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "dayfirst=True\n",
    "melb_df['Date'] = pd.to_datetime(melb_df['Date'], dayfirst=True)\n",
    "melb_df['WeekdaySale'] = melb_df['Date'].dt.dayofweek\n",
    "weekend_count = melb_df[(melb_df['WeekdaySale'] == 5) | (melb_df['WeekdaySale'] == 6)].shape[0]\n",
    "pivot = melb_df.pivot_table(\n",
    "    values='Price',\n",
    "    index='SellerG',\n",
    "    columns='Type',\n",
    "    aggfunc='mean',\n",
    "    fill_value=0)\n",
    "max_unit_price = pivot['u'].max()\n",
    "print(pivot[pivot['u'] == max_unit_price].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   index          13580 non-null  int64   \n",
      " 1   Suburb         13580 non-null  category\n",
      " 2   Address        13580 non-null  object  \n",
      " 3   Rooms          13580 non-null  int64   \n",
      " 4   Type           13580 non-null  object  \n",
      " 5   Price          13580 non-null  float64 \n",
      " 6   Method         13580 non-null  object  \n",
      " 7   SellerG        13580 non-null  object  \n",
      " 8   Date           13580 non-null  object  \n",
      " 9   Distance       13580 non-null  float64 \n",
      " 10  Postcode       13580 non-null  int64   \n",
      " 11  Bedroom        13580 non-null  int64   \n",
      " 12  Bathroom       13580 non-null  int64   \n",
      " 13  Car            13580 non-null  int64   \n",
      " 14  Landsize       13580 non-null  float64 \n",
      " 15  BuildingArea   13580 non-null  float64 \n",
      " 16  YearBuilt      13580 non-null  int64   \n",
      " 17  CouncilArea    12211 non-null  object  \n",
      " 18  Lattitude      13580 non-null  float64 \n",
      " 19  Longtitude     13580 non-null  float64 \n",
      " 20  Regionname     13580 non-null  object  \n",
      " 21  Propertycount  13580 non-null  int64   \n",
      " 22  Coordinates    13580 non-null  object  \n",
      "dtypes: category(1), float64(6), int64(8), object(8)\n",
      "memory usage: 2.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('data/melb_data_ps.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "popular_stypes =melb_df['Suburb'].value_counts().nlargest(119).index\n",
    "melb_df['Suburb'] = melb_df['Suburb'].apply(lambda x: x if x in popular_stypes else 'other')\n",
    "melb_df['Suburb'] = melb_df['Suburb'].astype('category') \n",
    "display(melb_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nick\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('data/melb_data_fe.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "melb_df['Date'] = pd.to_datetime(melb_df['Date'])\n",
    "cols_to_exclude = ['Date', 'Rooms', 'Bedroom', 'Bathroom', 'Car'] # список столбцов, которые мы не берём во внимание\n",
    "max_unique_count = 150 # задаём максимальное число уникальных категорий\n",
    "for col in melb_df.columns: # цикл по именам столбцов\n",
    "    if melb_df[col].nunique() < max_unique_count and col not in cols_to_exclude: # проверяем условие\n",
    "        melb_df[col] = melb_df[col].astype('category') # преобразуем тип столбца\n",
    "melb_df['WeekdaySale'] = melb_df['Date'].dt.dayofweek\n",
    "weekend_count = melb_df[(melb_df['WeekdaySale'] == 5) | (melb_df['WeekdaySale'] == 6)].shape[0]\n",
    "pivot = melb_df.pivot_table(\n",
    "    values='Price',\n",
    "    index='SellerG',\n",
    "    columns='Type',\n",
    "    aggfunc='mean',\n",
    "    fill_value=0)\n",
    "max_unit_price = pivot['unit'].max()\n",
    "print(pivot[pivot['unit'] == max_unit_price].index[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '‘' (U+2018) (999427813.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [694]\u001b[0;36m\u001b[0m\n\u001b[0;31m    movies = pd.read_csv(‘data/movies.csv’, sep=‘,’), sep=',')\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '‘' (U+2018)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "movies = pd.read_csv(‘data/movies.csv’, sep=‘,’), sep=',')\n",
    "ratings1 = pd.read_csv('data/ratings1.csv', sep=',')\n",
    "ratings2 = pd.read_csv('data/ratings2.csv', sep=',')\n",
    "dates = pd.read_csv('data/dates.csv', sep=',')\n",
    "ratings = pd.concat(\n",
    "    [ratings1, ratings2],\n",
    "    ignore_index=True\n",
    ")\n",
    "ratings = ratings.drop_duplicates(ignore_index=True)\n",
    "ratings_dates = pd.concat([ratings, dates], axis=1)\n",
    "dates['Date'] = pd.to_datetime(dates['Date'])\n",
    "years = dates['Date'].dt.year\n",
    "print('Mode year:', years.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30 18:45:03</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30 18:20:47</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30 18:37:04</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-07-30 19:03:35</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-07-30 18:48:51</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating                date                        title  \\\n",
       "0       1        1     4.0 2000-07-30 18:45:03             Toy Story (1995)   \n",
       "1       1        3     4.0 2000-07-30 18:20:47      Grumpier Old Men (1995)   \n",
       "2       1        6     4.0 2000-07-30 18:37:04                  Heat (1995)   \n",
       "3       1       47     5.0 2000-07-30 19:03:35  Seven (a.k.a. Se7en) (1995)   \n",
       "4       1       50     5.0 2000-07-30 18:48:51   Usual Suspects, The (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                               Comedy|Romance  \n",
       "2                        Action|Crime|Thriller  \n",
       "3                             Mystery|Thriller  \n",
       "4                       Crime|Mystery|Thriller  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "movies = pd.read_csv('data/movies.csv', sep=',')\n",
    "ratings1 = pd.read_csv('data/ratings1.csv', sep=',')\n",
    "ratings2 = pd.read_csv('data/ratings2.csv', sep=',')\n",
    "dates = pd.read_csv('data/dates.csv', sep=',')\n",
    "ratings = pd.concat(\n",
    "    [ratings1, ratings2],\n",
    "    ignore_index=True\n",
    ")\n",
    "ratings = ratings.drop_duplicates(ignore_index=True)\n",
    "ratings_dates = pd.concat([ratings, dates], axis=1)\n",
    "ratings_dates['date'] = pd.to_datetime(ratings_dates['date'])\n",
    "merged = ratings_dates.merge(\n",
    "    movies,\n",
    "    on='movieId',\n",
    "    how='left'\n",
    ")\n",
    "display(merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    0\n",
       "Name: Order ID, dtype: int64"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "products_df = pd.read_csv('data/products.csv', sep=';')\n",
    "orders_df = pd.read_csv('data/orders.csv', sep=';')\n",
    "orders_products = orders_df.merge(\n",
    "    products_df, \n",
    "    left_on='ID товара',\n",
    "    right_on='Product_ID',\n",
    "    how='left')\n",
    "orders_products.tail(1)['Order ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>genres</th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Action|Adventure</th>\n",
       "      <th>Action|Adventure|Animation</th>\n",
       "      <th>Action|Adventure|Animation|Children</th>\n",
       "      <th>Action|Adventure|Animation|Children|Comedy</th>\n",
       "      <th>Action|Adventure|Animation|Children|Comedy|Fantasy</th>\n",
       "      <th>Action|Adventure|Animation|Children|Comedy|IMAX</th>\n",
       "      <th>Action|Adventure|Animation|Children|Comedy|Romance</th>\n",
       "      <th>Action|Adventure|Animation|Children|Comedy|Sci-Fi</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance|Thriller</th>\n",
       "      <th>Romance|War</th>\n",
       "      <th>Romance|Western</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Sci-Fi|IMAX</th>\n",
       "      <th>Sci-Fi|Thriller</th>\n",
       "      <th>Sci-Fi|Thriller|IMAX</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.730769</td>\n",
       "      <td>3.454545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.838095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.538462</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.923077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.588235</td>\n",
       "      <td>3.738462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.087912</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.477273</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>4.304348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.277778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.375</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>4.136364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.464286</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.357143</td>\n",
       "      <td>3.413043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.107143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.411765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.735294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.421875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.656250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.964286</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>3.560976</td>\n",
       "      <td>3.800</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.565217</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.071429</td>\n",
       "      <td>3.764706</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.911765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>3.722222</td>\n",
       "      <td>3.750</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.925000</td>\n",
       "      <td>3.388889</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>3.807692</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.432432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.637931</td>\n",
       "      <td>3.527778</td>\n",
       "      <td>3.375</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.676471</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.864865</td>\n",
       "      <td>4.264706</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.152174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>3.676471</td>\n",
       "      <td>2.588235</td>\n",
       "      <td>3.397436</td>\n",
       "      <td>3.650</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.741935</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.128571</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.296296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows × 951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "genres       (no genres listed)    Action  Action|Adventure  \\\n",
       "year_rating                                                   \n",
       "1996                        NaN  2.730769          3.454545   \n",
       "1997                        NaN  3.538462          4.150000   \n",
       "1998                        NaN       NaN          4.200000   \n",
       "1999                        NaN       NaN          4.000000   \n",
       "2000                        NaN  2.588235          3.738462   \n",
       "2001                        NaN  3.000000          3.500000   \n",
       "2002                        NaN  2.750000          4.304348   \n",
       "2003                        NaN  3.833333          3.277778   \n",
       "2004                        NaN  2.700000          4.136364   \n",
       "2005                        NaN  3.357143          3.413043   \n",
       "2006                        NaN  2.166667          4.090909   \n",
       "2007                        NaN  2.583333          3.666667   \n",
       "2008                        NaN  3.000000          3.656250   \n",
       "2009                        NaN       NaN          3.714286   \n",
       "2010                        NaN  3.500000          3.437500   \n",
       "2011                        NaN  4.500000          3.888889   \n",
       "2012                        NaN  2.625000          3.900000   \n",
       "2013                        NaN  2.500000          3.833333   \n",
       "2014                        NaN       NaN          3.875000   \n",
       "2015                   0.500000  3.100000          3.560976   \n",
       "2016                   3.500000  3.545455          3.722222   \n",
       "2017                   3.000000  2.637931          3.527778   \n",
       "2018                   3.676471  2.588235          3.397436   \n",
       "\n",
       "genres       Action|Adventure|Animation  Action|Adventure|Animation|Children  \\\n",
       "year_rating                                                                    \n",
       "1996                                NaN                                  NaN   \n",
       "1997                                NaN                                  NaN   \n",
       "1998                                NaN                                  NaN   \n",
       "1999                                NaN                                  NaN   \n",
       "2000                                NaN                                  NaN   \n",
       "2001                                NaN                                  NaN   \n",
       "2002                                NaN                                  NaN   \n",
       "2003                                NaN                                  NaN   \n",
       "2004                                NaN                                  NaN   \n",
       "2005                                NaN                                  NaN   \n",
       "2006                                NaN                                  NaN   \n",
       "2007                                NaN                                  NaN   \n",
       "2008                                NaN                                  NaN   \n",
       "2009                                NaN                                  NaN   \n",
       "2010                                NaN                                  NaN   \n",
       "2011                                NaN                                  NaN   \n",
       "2012                                NaN                             4.000000   \n",
       "2013                                NaN                             3.000000   \n",
       "2014                              3.000                             3.500000   \n",
       "2015                              3.800                             3.666667   \n",
       "2016                              3.750                             3.833333   \n",
       "2017                              3.375                             3.500000   \n",
       "2018                              3.650                             3.166667   \n",
       "\n",
       "genres       Action|Adventure|Animation|Children|Comedy  \\\n",
       "year_rating                                               \n",
       "1996                                                NaN   \n",
       "1997                                                NaN   \n",
       "1998                                                NaN   \n",
       "1999                                                NaN   \n",
       "2000                                                NaN   \n",
       "2001                                                NaN   \n",
       "2002                                                NaN   \n",
       "2003                                                NaN   \n",
       "2004                                           4.000000   \n",
       "2005                                           4.107143   \n",
       "2006                                           3.833333   \n",
       "2007                                           3.846154   \n",
       "2008                                           4.125000   \n",
       "2009                                           3.900000   \n",
       "2010                                           4.333333   \n",
       "2011                                           3.500000   \n",
       "2012                                           3.785714   \n",
       "2013                                           4.333333   \n",
       "2014                                           3.250000   \n",
       "2015                                           3.565217   \n",
       "2016                                           3.925000   \n",
       "2017                                           3.676471   \n",
       "2018                                           3.741935   \n",
       "\n",
       "genres       Action|Adventure|Animation|Children|Comedy|Fantasy  \\\n",
       "year_rating                                                       \n",
       "1996                                                       NaN    \n",
       "1997                                                       NaN    \n",
       "1998                                                       NaN    \n",
       "1999                                                       NaN    \n",
       "2000                                                       NaN    \n",
       "2001                                                       NaN    \n",
       "2002                                                       NaN    \n",
       "2003                                                       NaN    \n",
       "2004                                                       NaN    \n",
       "2005                                                       NaN    \n",
       "2006                                                       NaN    \n",
       "2007                                                  3.000000    \n",
       "2008                                                  4.000000    \n",
       "2009                                                       NaN    \n",
       "2010                                                       NaN    \n",
       "2011                                                       NaN    \n",
       "2012                                                       NaN    \n",
       "2013                                                       NaN    \n",
       "2014                                                  3.833333    \n",
       "2015                                                  3.833333    \n",
       "2016                                                  3.388889    \n",
       "2017                                                  3.700000    \n",
       "2018                                                  4.142857    \n",
       "\n",
       "genres       Action|Adventure|Animation|Children|Comedy|IMAX  \\\n",
       "year_rating                                                    \n",
       "1996                                                     NaN   \n",
       "1997                                                     NaN   \n",
       "1998                                                     NaN   \n",
       "1999                                                     NaN   \n",
       "2000                                                     NaN   \n",
       "2001                                                     NaN   \n",
       "2002                                                     NaN   \n",
       "2003                                                     NaN   \n",
       "2004                                                     NaN   \n",
       "2005                                                     NaN   \n",
       "2006                                                     NaN   \n",
       "2007                                                     NaN   \n",
       "2008                                                     NaN   \n",
       "2009                                                3.250000   \n",
       "2010                                                3.500000   \n",
       "2011                                                     NaN   \n",
       "2012                                                3.550000   \n",
       "2013                                                5.000000   \n",
       "2014                                                3.500000   \n",
       "2015                                                3.375000   \n",
       "2016                                                3.666667   \n",
       "2017                                                1.000000   \n",
       "2018                                                3.700000   \n",
       "\n",
       "genres       Action|Adventure|Animation|Children|Comedy|Romance  \\\n",
       "year_rating                                                       \n",
       "1996                                                       NaN    \n",
       "1997                                                       NaN    \n",
       "1998                                                       NaN    \n",
       "1999                                                       NaN    \n",
       "2000                                                       NaN    \n",
       "2001                                                       NaN    \n",
       "2002                                                       NaN    \n",
       "2003                                                       NaN    \n",
       "2004                                                       NaN    \n",
       "2005                                                       NaN    \n",
       "2006                                                       NaN    \n",
       "2007                                                       NaN    \n",
       "2008                                                       NaN    \n",
       "2009                                                       NaN    \n",
       "2010                                                  3.000000    \n",
       "2011                                                       NaN    \n",
       "2012                                                  4.000000    \n",
       "2013                                                       NaN    \n",
       "2014                                                  4.000000    \n",
       "2015                                                  2.333333    \n",
       "2016                                                  1.000000    \n",
       "2017                                                  1.000000    \n",
       "2018                                                  2.500000    \n",
       "\n",
       "genres       Action|Adventure|Animation|Children|Comedy|Sci-Fi  ...  \\\n",
       "year_rating                                                     ...   \n",
       "1996                                                       NaN  ...   \n",
       "1997                                                       NaN  ...   \n",
       "1998                                                       NaN  ...   \n",
       "1999                                                       NaN  ...   \n",
       "2000                                                       NaN  ...   \n",
       "2001                                                       NaN  ...   \n",
       "2002                                                       NaN  ...   \n",
       "2003                                                       NaN  ...   \n",
       "2004                                                       NaN  ...   \n",
       "2005                                                       NaN  ...   \n",
       "2006                                                       3.0  ...   \n",
       "2007                                                       2.8  ...   \n",
       "2008                                                       3.5  ...   \n",
       "2009                                                       2.5  ...   \n",
       "2010                                                       NaN  ...   \n",
       "2011                                                       4.0  ...   \n",
       "2012                                                       NaN  ...   \n",
       "2013                                                       NaN  ...   \n",
       "2014                                                       NaN  ...   \n",
       "2015                                                       2.5  ...   \n",
       "2016                                                       4.0  ...   \n",
       "2017                                                       2.0  ...   \n",
       "2018                                                       4.0  ...   \n",
       "\n",
       "genres       Romance|Thriller  Romance|War  Romance|Western    Sci-Fi  \\\n",
       "year_rating                                                             \n",
       "1996                      NaN          NaN              NaN       NaN   \n",
       "1997                      NaN          NaN              NaN       NaN   \n",
       "1998                      NaN          NaN              NaN       NaN   \n",
       "1999                    2.000          NaN              NaN       NaN   \n",
       "2000                    4.000          NaN              3.0  3.416667   \n",
       "2001                      NaN          NaN              3.0  2.500000   \n",
       "2002                    3.000          NaN              NaN  3.750000   \n",
       "2003                    3.375          2.5              NaN  2.333333   \n",
       "2004                    3.000          3.0              3.5  2.125000   \n",
       "2005                    2.000          NaN              NaN  3.000000   \n",
       "2006                      NaN          NaN              NaN  0.500000   \n",
       "2007                    1.500          NaN              2.5  3.375000   \n",
       "2008                      NaN          NaN              NaN  3.125000   \n",
       "2009                      NaN          NaN              NaN  2.000000   \n",
       "2010                      NaN          NaN              NaN  4.000000   \n",
       "2011                      NaN          NaN              NaN  3.500000   \n",
       "2012                    2.500          NaN              NaN  4.166667   \n",
       "2013                      NaN          NaN              NaN  1.500000   \n",
       "2014                      NaN          NaN              NaN  2.500000   \n",
       "2015                      NaN          NaN              NaN  2.900000   \n",
       "2016                    2.500          NaN              NaN  3.555556   \n",
       "2017                    3.000          NaN              NaN  3.864865   \n",
       "2018                      NaN          NaN              NaN  3.128571   \n",
       "\n",
       "genres       Sci-Fi|IMAX  Sci-Fi|Thriller  Sci-Fi|Thriller|IMAX  Thriller  \\\n",
       "year_rating                                                                 \n",
       "1996                 NaN         2.666667                   NaN  3.838095   \n",
       "1997                 NaN         3.400000                   NaN  3.923077   \n",
       "1998                 NaN              NaN                   NaN  3.800000   \n",
       "1999                 NaN         4.000000                   NaN  3.700000   \n",
       "2000                 NaN         2.142857                   NaN  3.087912   \n",
       "2001                 NaN         2.500000                   NaN  3.477273   \n",
       "2002                 NaN         3.600000                   NaN  3.583333   \n",
       "2003                 NaN         3.142857                   NaN  3.250000   \n",
       "2004                 NaN              NaN                   NaN  3.464286   \n",
       "2005                 NaN         2.750000                   NaN  3.411765   \n",
       "2006                 NaN         4.500000                   NaN  3.735294   \n",
       "2007                 NaN         2.833333                   NaN  3.421875   \n",
       "2008                 NaN         3.000000                   NaN  3.333333   \n",
       "2009                 NaN         4.000000                   NaN  2.964286   \n",
       "2010                 NaN         2.500000                   NaN  2.833333   \n",
       "2011                 NaN         1.833333              4.000000  3.625000   \n",
       "2012                 NaN         3.500000              3.666667  3.083333   \n",
       "2013                 NaN         3.833333              4.000000  3.666667   \n",
       "2014            5.000000              NaN              4.000000  4.000000   \n",
       "2015            4.071429         3.764706              4.000000  2.911765   \n",
       "2016            3.807692         3.916667              3.666667  3.432432   \n",
       "2017            4.264706         3.750000              2.500000  3.152174   \n",
       "2018            3.500000         3.562500                   NaN  3.296296   \n",
       "\n",
       "genres       War   Western  \n",
       "year_rating                 \n",
       "1996         NaN  3.117647  \n",
       "1997         NaN  3.000000  \n",
       "1998         NaN       NaN  \n",
       "1999         4.5  4.000000  \n",
       "2000         3.0  4.058824  \n",
       "2001         3.0  3.111111  \n",
       "2002         3.5  3.000000  \n",
       "2003         3.0  4.000000  \n",
       "2004         3.0  3.800000  \n",
       "2005         NaN  4.500000  \n",
       "2006         NaN  3.625000  \n",
       "2007         NaN  3.000000  \n",
       "2008         NaN  4.000000  \n",
       "2009         4.0  3.375000  \n",
       "2010         NaN  3.666667  \n",
       "2011         NaN  4.000000  \n",
       "2012         NaN  4.100000  \n",
       "2013         NaN  4.000000  \n",
       "2014         NaN  4.000000  \n",
       "2015         NaN  3.900000  \n",
       "2016         NaN  3.958333  \n",
       "2017         NaN  2.933333  \n",
       "2018         NaN  3.611111  \n",
       "\n",
       "[23 rows x 951 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ratings_movies = pd.read_csv('data/ratings_movies.csv', sep=',')\n",
    "import re \n",
    "def get_year_release(arg):\n",
    "    #находим все слова по шаблону \"(DDDD)\"\n",
    "    candidates = re.findall(r'\\(\\d{4}\\)', arg) \n",
    "    # проверяем число вхождений\n",
    "    if len(candidates) > 0:\n",
    "        #если число вхождений больше 0,\n",
    "\t#очищаем строку от знаков \"(\" и \")\"\n",
    "        year = candidates[0].replace('(', '')\n",
    "        year = year.replace(')', '')\n",
    "        return int(year)\n",
    "    else:\n",
    "        #если год не указан, возвращаем None\n",
    "        return None\n",
    "ratings_movies['year_release'] = ratings_movies['title'].apply(get_year_release)\n",
    "ratings_movies['date'] = pd.to_datetime(ratings_movies['date'])\n",
    "ratings_movies['year_rating'] = ratings_movies['date'].dt.year\n",
    "pivot = ratings_movies.pivot_table(\n",
    "    index='year_rating',\n",
    "    columns='genres',\n",
    "    values='rating',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "display(pivot)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/41ymw9416szdry3f82rfxvr80000gn/T/ipykernel_20719/3701609911.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  events_2018.start_time = pd.to_datetime(events_2018.start_time, format='%Y-%m-%dT%H:%M:%S')\n",
      "/var/folders/2t/41ymw9416szdry3f82rfxvr80000gn/T/ipykernel_20719/3701609911.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  purchase_2018[\"event_type\"] = 'purchase'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "NaT\n",
      "count      0\n",
      "mean     NaT\n",
      "std      NaT\n",
      "min      NaT\n",
      "25%      NaT\n",
      "50%      NaT\n",
      "75%      NaT\n",
      "max      NaT\n",
      "Name: timedelta, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "purchase_df = pd.read_csv('data/purchase.csv', sep=',')\n",
    "events_df = pd.read_csv('data/7_4_Events.csv', sep=',')\n",
    "condition = (events_df.start_time >= '2018-01-01') & (events_df.start_time < '2019-01-01') & (events_df.event_type =='registration')\n",
    "registered = events_df[condition]['user_id'].to_list()\n",
    "events_2018 = events_df[events_df.user_id.isin(registered)]\n",
    "events_2018.start_time = pd.to_datetime(events_2018.start_time, format='%Y-%m-%dT%H:%M:%S')\n",
    "purchase_2018 = purchase_df[purchase_df['user_id'].isin(registered)]\n",
    "registered_users_count = events_2018[events_2018[\"event_type\"] == \"registration\"][\n",
    "    \"user_id\"\n",
    "].nunique()\n",
    "tutorial_start_users_count = events_2018[events_2018[\"event_type\"] == \"tutorial_start\"][\n",
    "    \"user_id\"\n",
    "].nunique()\n",
    "tutorial_finish_users_count = events_2018[events_2018[\"event_type\"] == \"tutorial_finish\"][\n",
    "    \"user_id\"\n",
    "].nunique()\n",
    "level_choice_users_count = events_2018[events_2018[\"event_type\"] == \"level_choice\"][\n",
    "    \"user_id\"\n",
    "].nunique()\n",
    "training_choice_users_count = events_2018[events_2018[\"event_type\"] == \"pack_choice\"][\n",
    "    \"user_id\"\n",
    "].nunique()\n",
    "paying_users_count = purchase_2018[\"user_id\"].nunique()\n",
    "percent_of_paying_users = paying_users_count / training_choice_users_count\n",
    "purchase_2018[\"event_type\"] = 'purchase'\n",
    "events_2018 = events_2018.rename(columns={\"id\": \"event_id\"})\n",
    "purchase_2018 = purchase_2018.rename(columns={\"id\": \"purchase_id\"})\n",
    "total_events_df = pd.concat([events_2018,purchase_2018],sort=False)\n",
    "total_events_df = total_events_df.reset_index(drop=True).sort_values('start_time')\n",
    "user_path_df = (\n",
    "    total_events_df.groupby([\"user_id\"])[\"event_type\"].apply(list).reset_index()\n",
    ")\n",
    "user_path_df[\"event_path\"] = user_path_df[\"event_type\"].apply(lambda x: \" > \".join(x))\n",
    "user_paths = (\n",
    "    user_path_df.groupby([\"event_path\"])[\"user_id\"]\n",
    "    .nunique()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "registration_df = total_events_df[total_events_df['event_type'] == 'registration']\n",
    "registration_df = registration_df[[\"user_id\", \"start_time\"]].rename(\n",
    "    columns={\"start_time\": \"registration_time\"})\n",
    "tutorial_start_df = total_events_df[total_events_df['event_type'] == 'tutorial_start']\n",
    "tutorial_start_df['user_id'].value_counts().mean()\n",
    "tutorial_start_df_wo_duplicates = tutorial_start_df.sort_values(\n",
    "    \"start_time\"\n",
    ").drop_duplicates(\"user_id\")\n",
    "tutorial_start_df_wo_duplicates = tutorial_start_df_wo_duplicates[\n",
    "    [\"user_id\", \"tutorial_id\", \"start_time\"]\n",
    "].rename(columns={\"start_time\": \"tutorial_start_time\"})\n",
    "merged_df = registration_df.merge(tutorial_start_df_wo_duplicates, on=\"user_id\", how=\"inner\")\n",
    "merged_df[\"timedelta\"] = (merged_df[\"tutorial_start_time\"] - merged_df[\"registration_time\"])\n",
    "tutorial_finish_df = total_events_df[total_events_df[\"event_type\"] == \"tutorial_finish\"]\n",
    "first_tutorial_ids = tutorial_start_df_wo_duplicates[\"tutorial_id\"].unique()\n",
    "tutorial_finish_df = tutorial_finish_df[\n",
    "    tutorial_finish_df[\"tutorial_id\"].isin(first_tutorial_ids)]\n",
    "tutorial_finish_df['user_id'].value_counts().mean()\n",
    "tutorial_finish_df = tutorial_finish_df[[\"user_id\", \"start_time\"]].rename(\n",
    "    columns={\"start_time\": \"tutorial_finish_time\"}\n",
    ")\n",
    "merged_df_2 = tutorial_start_df_wo_duplicates.merge(\n",
    "    tutorial_finish_df, on=\"user_id\", how=\"inner\"\n",
    ")\n",
    "merged_df_2[\"timedelta\"] = (\n",
    "    merged_df_2[\"tutorial_finish_time\"] - merged_df_2[\"tutorial_start_time\"]\n",
    ")\n",
    "merged_df_2.head()\n",
    "level_choice_df = total_events_df[total_events_df[\"event_type\"] == \"level_choice\"]\n",
    "print(level_choice_df[\"user_id\"].value_counts().mean())\n",
    "level_choice_df = level_choice_df[[\"user_id\", \"start_time\"]].rename(\n",
    "    columns={\"start_time\": \"level_choice_time\"}\n",
    ")\n",
    "merged_df_3 = registration_df.merge(level_choice_df, on=\"user_id\", how=\"inner\")\n",
    "merged_df_3[\"timedelta\"] = (\n",
    "    merged_df_3[\"level_choice_time\"] - merged_df_3[\"registration_time\"]\n",
    ")\n",
    "tutorial_pack_df = total_events_df[total_events_df[\"event_type\"] == \"pack_choice\"]\n",
    "tutorial_pack_df = tutorial_pack_df[[\"user_id\", \"start_time\"]].rename(columns={\"start_time\": \"tutorial_pack_time\"})\n",
    "merged_df_4 = tutorial_pack_df.merge(level_choice_df, on=\"user_id\", how=\"inner\")\n",
    "merged_df_4[\"timedelta\"] = (\n",
    "    merged_df_4[\"tutorial_pack_time\"] - merged_df_4[\"level_choice_time\"]\n",
    ")\n",
    "first_purchase_df = total_events_df[total_events_df['event_type'] == 'purchase']\n",
    "print(first_purchase_df[\"user_id\"].value_counts().mean())\n",
    "first_purchase_df = first_purchase_df[[\"user_id\", \"start_time\"]].rename(\n",
    "    columns={\"start_time\": \"first_purchase_time\"}\n",
    ")\n",
    "merged_df_5 = tutorial_pack_df.merge(first_purchase_df, on=\"user_id\", how=\"inner\")\n",
    "merged_df_5[\"timedelta\"] = (merged_df_5[\"first_purchase_time\"] - merged_df_5[\"tutorial_pack_time\"]\n",
    ")\n",
    "print(merged_df_5[\"timedelta\"].mean())\n",
    "print(merged_df_5[\"timedelta\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/41ymw9416szdry3f82rfxvr80000gn/T/ipykernel_20719/253431165.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  events_2018.start_time = pd.to_datetime(events_2018.start_time, format='%Y-%m-%dT%H:%M:%S')\n",
      "/var/folders/2t/41ymw9416szdry3f82rfxvr80000gn/T/ipykernel_20719/253431165.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  purchase_2018.event_datetime = pd.to_datetime(purchase_2018.event_datetime, format='%Y-%m-%dT%H:%M:%S')\n",
      "/var/folders/2t/41ymw9416szdry3f82rfxvr80000gn/T/ipykernel_20719/253431165.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  purchase_2018[\"event_type\"] = 'purchase'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "3 days 17:46:53.403125\n",
      "count                         1600\n",
      "mean        3 days 17:46:53.403125\n",
      "std      2 days 04:37:20.225124289\n",
      "min                0 days 00:44:50\n",
      "25%         1 days 21:24:13.250000\n",
      "50%         3 days 12:51:25.500000\n",
      "75%         5 days 09:42:13.750000\n",
      "max               10 days 18:33:59\n",
      "Name: timedelta, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "purchase_df = pd.read_csv('data/purchase.csv', sep=',')\n",
    "events_df = pd.read_csv('data/7_4_Events.csv', sep=',')\n",
    "condition = (events_df.start_time >= '2018-01-01') & (events_df.start_time < '2019-01-01') & (events_df.event_type =='registration')\n",
    "registered = events_df[condition]['user_id'].to_list()\n",
    "events_2018 = events_df[events_df.user_id.isin(registered)]\n",
    "events_2018.start_time = pd.to_datetime(events_2018.start_time, format='%Y-%m-%dT%H:%M:%S')\n",
    "purchase_2018 = purchase_df[purchase_df['user_id'].isin(registered)]\n",
    "purchase_2018.event_datetime = pd.to_datetime(purchase_2018.event_datetime, format='%Y-%m-%dT%H:%M:%S')\n",
    "registered_users_count = events_2018[events_2018[\"event_type\"] == \"registration\"][\n",
    "    \"user_id\"\n",
    "].nunique()\n",
    "tutorial_start_users_count = events_2018[events_2018[\"event_type\"] == \"tutorial_start\"][\n",
    "    \"user_id\"\n",
    "].nunique()\n",
    "tutorial_finish_users_count = events_2018[events_2018[\"event_type\"] == \"tutorial_finish\"][\n",
    "    \"user_id\"\n",
    "].nunique()\n",
    "level_choice_users_count = events_2018[events_2018[\"event_type\"] == \"level_choice\"][\n",
    "    \"user_id\"\n",
    "].nunique()\n",
    "training_choice_users_count = events_2018[events_2018[\"event_type\"] == \"pack_choice\"][\n",
    "    \"user_id\"\n",
    "].nunique()\n",
    "paying_users_count = purchase_2018[\"user_id\"].nunique()\n",
    "percent_of_paying_users = paying_users_count / training_choice_users_count\n",
    "purchase_2018[\"event_type\"] = 'purchase'\n",
    "events_2018 = events_2018.rename(columns={\"id\": \"event_id\"})\n",
    "purchase_2018 = purchase_2018.rename(columns={\"id\": \"purchase_id\"})\n",
    "total_events_df = pd.concat([events_2018,purchase_2018],sort=False)\n",
    "total_events_df = total_events_df.reset_index(drop=True).sort_values('start_time')\n",
    "user_path_df = (\n",
    "    total_events_df.groupby([\"user_id\"])[\"event_type\"].apply(list).reset_index()\n",
    ")\n",
    "user_path_df[\"event_path\"] = user_path_df[\"event_type\"].apply(lambda x: \" > \".join(x))\n",
    "user_paths = (\n",
    "    user_path_df.groupby([\"event_path\"])[\"user_id\"]\n",
    "    .nunique()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "registration_df = total_events_df[total_events_df['event_type'] == 'registration']\n",
    "registration_df = registration_df[[\"user_id\", \"start_time\"]].rename(\n",
    "    columns={\"start_time\": \"registration_time\"})\n",
    "tutorial_start_df = total_events_df[total_events_df['event_type'] == 'tutorial_start']\n",
    "tutorial_start_df['user_id'].value_counts().mean()\n",
    "tutorial_start_df_wo_duplicates = tutorial_start_df.sort_values(\n",
    "    \"start_time\"\n",
    ").drop_duplicates(\"user_id\")\n",
    "tutorial_start_df_wo_duplicates = tutorial_start_df_wo_duplicates[\n",
    "    [\"user_id\", \"tutorial_id\", \"start_time\"]\n",
    "].rename(columns={\"start_time\": \"tutorial_start_time\"})\n",
    "merged_df = registration_df.merge(tutorial_start_df_wo_duplicates, on=\"user_id\", how=\"inner\")\n",
    "merged_df[\"timedelta\"] = (merged_df[\"tutorial_start_time\"] - merged_df[\"registration_time\"])\n",
    "tutorial_finish_df = total_events_df[total_events_df[\"event_type\"] == \"tutorial_finish\"]\n",
    "first_tutorial_ids = tutorial_start_df_wo_duplicates[\"tutorial_id\"].unique()\n",
    "tutorial_finish_df = tutorial_finish_df[\n",
    "    tutorial_finish_df[\"tutorial_id\"].isin(first_tutorial_ids)]\n",
    "tutorial_finish_df['user_id'].value_counts().mean()\n",
    "tutorial_finish_df = tutorial_finish_df[[\"user_id\", \"start_time\"]].rename(\n",
    "    columns={\"start_time\": \"tutorial_finish_time\"}\n",
    ")\n",
    "merged_df_2 = tutorial_start_df_wo_duplicates.merge(\n",
    "    tutorial_finish_df, on=\"user_id\", how=\"inner\"\n",
    ")\n",
    "merged_df_2[\"timedelta\"] = (\n",
    "    merged_df_2[\"tutorial_finish_time\"] - merged_df_2[\"tutorial_start_time\"]\n",
    ")\n",
    "merged_df_2.head()\n",
    "level_choice_df = total_events_df[total_events_df[\"event_type\"] == \"level_choice\"]\n",
    "level_choice_df = level_choice_df[[\"user_id\", \"start_time\"]].rename(\n",
    "    columns={\"start_time\": \"level_choice_time\"}\n",
    ")\n",
    "merged_df_3 = registration_df.merge(level_choice_df, on=\"user_id\", how=\"inner\")\n",
    "merged_df_3[\"timedelta\"] = (\n",
    "    merged_df_3[\"level_choice_time\"] - merged_df_3[\"registration_time\"]\n",
    ")\n",
    "tutorial_pack_df = total_events_df[total_events_df[\"event_type\"] == \"pack_choice\"]\n",
    "tutorial_pack_df = tutorial_pack_df[[\"user_id\", \"start_time\"]].rename(columns={\"start_time\": \"tutorial_pack_time\"})\n",
    "merged_df_4 = tutorial_pack_df.merge(level_choice_df, on=\"user_id\", how=\"inner\")\n",
    "merged_df_4[\"timedelta\"] = (\n",
    "    merged_df_4[\"tutorial_pack_time\"] - merged_df_4[\"level_choice_time\"]\n",
    ")\n",
    "first_purchase_df = total_events_df[total_events_df['event_type'] == 'purchase']\n",
    "print(first_purchase_df['user_id'].value_counts().mean())\n",
    "first_purchase_df = first_purchase_df[['user_id', 'event_datetime']].rename(\n",
    "    columns={'event_datetime': 'first_purchase_time'}\n",
    ")\n",
    "merged_df_5 = tutorial_pack_df.merge(first_purchase_df, on='user_id', how='inner')\n",
    "merged_df_5['timedelta'] = (\n",
    "    merged_df_5['first_purchase_time'] - merged_df_5['tutorial_pack_time']\n",
    ")\n",
    "print(merged_df_5['timedelta'].mean())\n",
    "print(merged_df_5['timedelta'].describe())\n",
    "users_with_finished_tutorial = total_events_df[\n",
    "    total_events_df[\"event_type\"] == \"tutorial_finish\"\n",
    "][\"user_id\"].unique()\n",
    "users_with_started_tutorial = total_events_df[\n",
    "    total_events_df[\"event_type\"] == \"tutorial_start\"\n",
    "][\"user_id\"].unique()\n",
    "set_users_with_started_tutorial = set(users_with_started_tutorial)\n",
    "set_users_not_finished_but_started_tutorial = (\n",
    "    set_users_with_started_tutorial.difference(set(users_with_finished_tutorial))\n",
    ")\n",
    "all_users = total_events_df[\"user_id\"].unique()\n",
    "set_all_users = set(all_users)\n",
    "set_users_not_started_tutorial = set_all_users.difference(\n",
    "    set_users_with_started_tutorial)\n",
    "purchase_df_1 = purchase_df[purchase_df[\"user_id\"].isin(users_with_finished_tutorial)]\n",
    "purchase_df_2 = purchase_df[purchase_df[\"user_id\"].isin(set_users_not_finished_but_started_tutorial)]\n",
    "purchase_df_3 = purchase_df[purchase_df[\"user_id\"].isin(set_users_not_started_tutorial)]\n",
    "percent_of_purchase_3 = purchase_df_3[\"user_id\"].nunique() / len(set_users_not_started_tutorial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.05263157894737\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "log=pd.read_csv('data/log.csv', header=None)\n",
    "log.columns=['user_id', 'time', 'bet','win']\n",
    "users = pd.read_csv('data/users.csv', sep='\\t', encoding=\"koi8-r\")\n",
    "users.columns = ['user_id', 'email', 'geo']\n",
    "users.user_id = users.user_id.apply(lambda x: x.lower())   \n",
    "log = log[log.user_id != '#error']  \n",
    "log.user_id = log.user_id.str.split(' - ').apply(lambda x: x[1])  \n",
    "log.time = log.time.str.strip('[')\n",
    "log['time'] = pd.to_datetime(log['time'], format='%Y-%m-%d %H:%M:%S')\n",
    "log[\"bet\"] = log[\"bet\"].fillna(0)\n",
    "log[\"win\"] = log[\"win\"].fillna(0)\n",
    "log[\"net\"] = log[\"win\"] - log[\"bet\"]\n",
    "df = pd.merge(users, log, on='user_id')\n",
    "min_2 = df[df.bet>0].groupby('user_id').time.min() \n",
    "min_1 = df[df.bet==0].groupby('user_id').time.min()\n",
    "s = []\n",
    "for i in (min_2-min_1):\n",
    "    if not str(i)[0] == '-':\n",
    "        s.append(i.days)\n",
    "print(sum(s)/len(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'user_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/denis/Desktop/IDE/35.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/denis/Desktop/IDE/35.ipynb#ch0000013?line=1'>2</a>\u001b[0m log \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mdata/log.csv\u001b[39m\u001b[39m\"\u001b[39m, header \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/denis/Desktop/IDE/35.ipynb#ch0000013?line=2'>3</a>\u001b[0m users \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mdata/users.csv\u001b[39m\u001b[39m\"\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkoi8_r\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/denis/Desktop/IDE/35.ipynb#ch0000013?line=3'>4</a>\u001b[0m log \u001b[39m=\u001b[39m log[log\u001b[39m.\u001b[39;49muser_id \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m#error\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/denis/Desktop/IDE/35.ipynb#ch0000013?line=4'>5</a>\u001b[0m log\u001b[39m.\u001b[39muser_id \u001b[39m=\u001b[39m log\u001b[39m.\u001b[39muser_id\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m - \u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m1\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/denis/Desktop/IDE/35.ipynb#ch0000013?line=5'>6</a>\u001b[0m log\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbet\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwin\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'user_id'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "log = pd.read_csv(\"data/log.csv\", header = None)\n",
    "users = pd.read_csv(\"data/users.csv\", sep=\"\\t\", encoding=\"koi8_r\")\n",
    "log = log[log.user_id != \"#error\"]\n",
    "log.user_id = log.user_id.str.split(\" - \").apply(lambda x: x[1])\n",
    "log.columns = [\"user_id\", \"time\", \"bet\", \"win\"]\n",
    "users.columns = ['user_id', 'email', 'geo']\n",
    "users.user_id = users.user_id.apply(lambda x: x.lower())\n",
    "log['time']=log['time'].str.replace('[','')\n",
    "log[\"time\"] = pd.to_datetime(log[\"time\"])\n",
    "log.dropna()\n",
    "hour = log[\"time\"].dt.hour\n",
    "log[\"bet\"] = log[\"bet\"].fillna(0)\n",
    "log[\"win\"] = log[\"win\"].fillna(0)\n",
    "log[\"net\"] = log[\"win\"] - log[\"bet\"]\n",
    "lu=pd.merge(log, users, on='user_id') \n",
    "lu.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "986"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "log=pd.read_csv('data/log.csv', header=None)\n",
    "log.columns=['user_id', 'time', 'bet', 'win']\n",
    "len(log.drop_duplicates(subset=['user_id', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample = pd.read_csv(\"data/sample.csv\")\n",
    "sample.columns = [\"name\", \"city\", \"age\", \"profession\"]\n",
    "sample4=sample[~sample.city.str.match(\"о\", na=False)]\n",
    "def age_category(age):\n",
    "    if age < 23:\n",
    "        return \"молодой\";\n",
    "    elif 23 <= age > 35:\n",
    "        return \"средний\";\n",
    "    elif age > 35:\n",
    "        return \"зрелый\"\n",
    "sample['Age_category'] = sample.age.apply(age_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Accumanst@gmail.com', 'Advismowr@mail.ru', 'Anachso@ukr.net',\n",
       "       'Antecia@inbox.ru', 'Balliaryva@ukr.net', 'Bigbytech@rambler.ru',\n",
       "       'Billionon@rambler.ru', 'BloggerJan@yahoo', 'Blueterva@ya.ru',\n",
       "       'Bootrasync@ukr.net', 'Borgueriac@ukr.net', 'Boxfixiteicloud.com',\n",
       "       'BraceWalker@bk.ru', 'Bradleyerat@rambler.ru', 'BullSpice@ukr.net',\n",
       "       'ByteTale@gmail.com', 'CapoGrand@rambler.ru', 'Cavotin@bk.ru',\n",
       "       'Chapterpl@yahoo.com', 'Chicapplin@gmail.com',\n",
       "       'Chikkaverle@icloud.com', 'Cincomphite@mail.ru',\n",
       "       'Decitere@mail.ru', 'DirtyChiri@ya.ru', 'Ever2free@inbox.ru',\n",
       "       'Exploator@ukr.net', 'EyesRae@inbox.ru', 'Fainvenu@icloud.com',\n",
       "       'FestiveAway@inbox.ru', 'Foreveracis@rambler.ru',\n",
       "       'ForlifeLatest@yahoo.com', 'FraserBlue@mail.ru',\n",
       "       'Freenson@inbox.ru', 'GazetteWas@yandex.ru', 'GlitzDas@yahoo.com',\n",
       "       'Gloxixir@ya.ru', 'Goriness@rambler.ru', 'Granilabe@inbox.ru',\n",
       "       'Grundymeat@ya.ru', 'Haystenvi@yandex.ru', 'Hetstact@yandex.ru',\n",
       "       'Hostener@gmail.com', nan, 'Infernody@ya.ru', 'Inserex@inbox.ru',\n",
       "       'Jectiolo@gmail.com', 'JimGlitz@ya.ru', 'Kalismed@bk.ru',\n",
       "       'Kenjinxte@rambler.ru', 'Kinkenbo@mail.ru',\n",
       "       'Kittysineos@rambler.ru', 'Knightstra@icloud.com',\n",
       "       'Kryptoburs@yahoo.com', 'Lassour@ukr.net', 'Latinarysa@rambler.ru',\n",
       "       'Lessomaire@rambler.ru', 'Lipsxiptp@yahoo.com',\n",
       "       'Loqutio@yandex.ru', 'Lyfernozoi@inbox.ru', 'Magazineli@ya.ru',\n",
       "       'Magazinetc@yahoo.com', 'Mailitry@ya.ru', 'Manionoe@ukr.net',\n",
       "       'MediaLead@rambler.ru', 'MoPoet@yahoo.com', 'Muchiple@yahoo.com',\n",
       "       'NumClear@bk.ru', 'NumTrendy@mail.ru', 'Paleoso@ukr.net',\n",
       "       'Paviatery@ukr.net', 'Peytzke@mail.ru', 'Pinkelysi@ya.ru',\n",
       "       'PleasantKeeper@ukr.net', 'PongCute@mail.ru',\n",
       "       'Prestigenp@inbox.ru', 'PricelessJuz@rambler.ru', 'Prinesbr@bk.ru',\n",
       "       'RosesTight@gmail.com', 'Roycess@rambler.ru',\n",
       "       'Sandpoist@gmail.com', 'Schwire@bk.ru', 'Seenomvura@yahoo.com',\n",
       "       'ShardDivision@icloud.com', 'Sianscot@yandex.ru',\n",
       "       'Somberyant@mail.ru', 'SpyderSpin@bk.ru', 'Stacile@yahoo.com',\n",
       "       'Stargalux@gmail.com', 'Styledget@rambler.ru',\n",
       "       'Sumollerno@inbox.ru', 'SupremeSynchro@rambler.ru',\n",
       "       'Therick@yahoo.com', 'Topictition@rambler.ru', 'Transky@yandex.ru',\n",
       "       'Trantawe@yandex.ru', 'UpdatesCurious@yahoo.com',\n",
       "       'V2artierso@mail.ru', 'Vashoterlo@bk.ru', 'Visuareda@yahoo.com',\n",
       "       'Aavast@ya.ru'], dtype=object)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "users = pd.read_csv(\"data/users.csv\", sep=\"\\t\", encoding=\"koi8_r\")\n",
    "users.columns = [\"user_id\", \"email\", \"geo\"]\n",
    "users.email.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italian\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "with open(\"data/recipes.json\") as f:  # Открываем файл и связываем его с объектом \"f\"\n",
    "    recipes = json.load(f)\n",
    "cuisines = [] # создаём пустой список для хранения уникальных значений кухонь\n",
    "for recipe in recipes: # начинаем перебор всех рецептов\n",
    "    if not(recipe['cuisine'] in cuisines): # если тип кухни текущего блюда ещё не встречался\n",
    "        cuisines.append(recipe['cuisine']) # добавляем его к списку cuisines\n",
    "valreccuisine = {} # Создаём пустой словарь для хранения информации об количествах рецептов в каждой кухне\n",
    "for item in cuisines: # Перебираем список кухонь\n",
    "    valreccuisine[item] = 0 # Добавляем в словарь ключ, соответствующий очередной кухне\n",
    "for recipe in recipes: # Перебираем список рецептов\n",
    "    valreccuisine[recipe['cuisine']] += 1 # Увеличиваем значение нужного ключа в словаре на 1\n",
    "            \n",
    "print(max(valreccuisine, key=valreccuisine.get))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кура price 40\n",
      "Кура weight 300\n",
      "Кура class Мясо\n",
      "\n",
      "Греча price 20\n",
      "Греча weight 200\n",
      "Греча class Крупа\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "new_root = ET.Element('menu')\n",
    "dish1 = ET.SubElement(new_root, 'dish', name='Кура')\n",
    "dish2 = ET.SubElement(new_root, 'dish', name='Греча')\n",
    "price1 = ET.SubElement(dish1, \"price\").text = \"40\"\n",
    "weight1 = ET.SubElement(dish1, \"weight\").text = \"300\"\n",
    "class1 = ET.SubElement(dish1, \"class\").text = \"Мясо\"\n",
    "price2 = ET.SubElement(dish2, \"price\").text = \"20\"\n",
    "weight2 = ET.SubElement(dish2, \"weight\").text = \"200\"\n",
    "class2 = ET.SubElement(dish2, \"class\").text = \"Крупа\"\n",
    "for dish in new_root:\n",
    "    for param in dish:\n",
    "        print(dish.attrib['name'], param.tag, param.text)\n",
    "    print()\n",
    "new_root_string = ET.tostring(new_root)\n",
    "with open(\"new_menu.xml\", \"wb\") as f:\n",
    "    f.write(new_root_string)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2328b28135b16d6905de1916ec36468d7d9b4dc5f173df5d6e03514953892388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
